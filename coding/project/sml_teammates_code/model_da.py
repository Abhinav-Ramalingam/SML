# -*- coding: utf-8 -*-
"""model_da.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ihEVYP8Q6Xw6HfuY7oOngKxEI39kbc78
"""

import os
import numpy as np
import pandas as pd
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    roc_curve,
    precision_recall_curve,
    accuracy_score,
    confusion_matrix,
    ConfusionMatrixDisplay,
    f1_score,
    make_scorer  # Imported make_scorer
)

# Set random seed for reproducibility
np.random.seed(32)

# Read the CSV file
file_path = 'training.csv'
df = pd.read_csv(file_path)

# Split the data into training and testing sets (80%-20%)
X = df.drop(columns=['increase_stock'])  # Features
y = df['increase_stock']  # Target

# Split the data into training and testing sets
X = df.drop(columns=['increase_stock'])  # Features
y = df['increase_stock']  # Target

# Split the data into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=32, stratify=y
)

# Preprocessing: Cyclic encoding for 'hour_of_day', 'day_of_week', and 'month'
for df_split in [X_train, X_test]:
    df_split.loc[:, 'hour_sin'] = np.sin(2 * np.pi * df_split['hour_of_day'] / 24)
    df_split.loc[:, 'hour_cos'] = np.cos(2 * np.pi * df_split['hour_of_day'] / 24)
    df_split.loc[:, 'day_sin'] = np.sin(2 * np.pi * df_split['day_of_week'] / 7)
    df_split.loc[:, 'day_cos'] = np.cos(2 * np.pi * df_split['day_of_week'] / 7)
    df_split.loc[:, 'month_sin'] = np.sin(2 * np.pi * df_split['month'] / 12)
    df_split.loc[:, 'month_cos'] = np.cos(2 * np.pi * df_split['month'] / 12)

# Selecting final features (exclude original cyclic columns)
final_features = [
    'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos',
    'weekday', 'summertime', 'temp', 'dew', 'humidity', 'precip', 'snowdepth', 'windspeed', 'visibility'
]

X_train = X_train[final_features]
X_test = X_test[final_features]

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

## LDA
print("LDA:")
print("===\n")

# Initialize LDA
lda = LinearDiscriminantAnalysis()

# LDA - train the LDA model on the training data
lda.fit(X_train, y_train)

# LDA - predict on the test data
y_pred = lda.predict(X_test)

# Perform 5-fold cross-validation
cv_scores = cross_val_score(lda, X_train_scaled, y_train, cv=5, scoring='f1_macro')  # Replace 'accuracy' with your metric of choice

# Results
print("Cross-validation scores:", cv_scores)
print("Mean accuracy:", cv_scores.mean())
print("Standard deviation:", cv_scores.std())

# LDA - evaluate the LDA model
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

## LDA with grid search
print("LDA with grid search:")
print("=====================\n")

# Initialize LDA
lda = LinearDiscriminantAnalysis()

# Grid search
param_grid = [ # Define the parameter grid
    {'solver': ['svd'], 'shrinkage': [None]},  # No shrinkage for 'svd'
    {'solver': ['lsqr', 'eigen'], 'shrinkage': [None, 'auto', 0.1, 0.5, 0.9]},
]
grid_search = GridSearchCV(lda, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_scaled, y_train)

# Best parameters
print("Best parameters:", grid_search.best_params_)
print("Best cross-validation score:", grid_search.best_score_)
# Best parameters: {'n_components': None, 'shrinkage': 0.1, 'solver': 'lsqr'}
# Best cross-validation score: 0.8671875

best_lda = grid_search.best_estimator_
y_pred = best_lda.predict(X_test_scaled)
## y_pred_prob = best_lda.predict_proba(X_test_scaled)[:, 1]

# Perform 5-fold cross-validation
cv_scores = cross_val_score(lda, X_train_scaled, y_train, cv=5, scoring='f1_macro')  # Replace 'accuracy' with your metric of choice

# Results
print("\nCross-validation scores:", cv_scores)
print("Mean accuracy:", cv_scores.mean())
print("Standard deviation:", cv_scores.std())

# LDA - evaluate the LDA model
print("\nTest Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

## QDA
print("QDA:")
print("===\n")

# Initialize QDA
qda = QuadraticDiscriminantAnalysis()

# QDA - train the LDA model on the training data
qda.fit(X_train, y_train)

# QDA - predict on the test data
y_pred = qda.predict(X_test)

# Perform 5-fold cross-validation
cv_scores = cross_val_score(qda, X_train_scaled, y_train, cv=5, scoring='f1_macro')  # Replace 'accuracy' with your metric of choice

# Results
print("Cross-validation scores:", cv_scores)
print("Mean accuracy:", cv_scores.mean())
print("Standard deviation:", cv_scores.std())

# QDA - evaluate the QDA model
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# QDA with Grid Search
print("QDA with Grid Search:")
print("=====================\n")

# Initialize the QDA model
qda = QuadraticDiscriminantAnalysis()

# Define the hyperparameter grid
param_grid = {
    'reg_param': [0.0, 0.1, 0.2, 0.5, 0.9, 1.0],  # Regularization parameter
    'tol': [1e-4, 1e-3, 1e-2],  # Tolerance for convergence
}

# Perform grid search with 5-fold cross-validation
grid_search = GridSearchCV(qda, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_scaled, y_train)

# Display best parameters and score
print("Best parameters:", grid_search.best_params_)
print("Best cross-validation score:", grid_search.best_score_)

# Train the best QDA model found
best_qda = grid_search.best_estimator_

# Perform 5-fold cross-validation using F1-score (or any other metric)
cv_scores = cross_val_score(best_qda, X_train_scaled, y_train, cv=5, scoring='f1_macro')
print("\nCross-validation F1 scores:", cv_scores)
print("Mean F1 score:", cv_scores.mean())
print("Standard deviation:", cv_scores.std())

# Make predictions on the test set
y_pred = best_qda.predict(X_test_scaled)

# Evaluate the model on the test set
print("\nTest Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))