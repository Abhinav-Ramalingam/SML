{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    make_scorer,  # Imported make_scorer\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all values in the 'snow' column are zero\n",
    "if (df['snow'] == 0).all():\n",
    "    print(\"Every value in the 'snow' column is zero.\")\n",
    "else:\n",
    "    print(\"Not every value in the 'snow' column is zero.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'snow' column\n",
    "df = df.drop(columns=['snow'])\n",
    "print(\"'snow' column removed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle Missing Values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Handle Target Variable Encoding\n",
    "df['increase_stock'] = df['increase_stock'].map({'low_bike_demand': 0, 'high_bike_demand': 1})\n",
    "\n",
    "# Cyclic Encoding for 'hour_of_day', 'day_of_week', and 'month'\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split the dataset into training and testing sets (80%-20%) with random_state=32 for reproducibility\n",
    "X = df.drop(columns=['increase_stock'])\n",
    "y = df['increase_stock']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32, stratify=y)\n",
    "\n",
    "print(y)\n",
    "\n",
    "# Display the updated DataFrame with PCA components\n",
    "print(\"Shape of X_train after PCA:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Shape of y_train:\")\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handling Outliers using Isolation Forest (for highly skewed variables)\n",
    "features = ['precip', 'snowdepth', 'visibility']\n",
    "X_outlier = pd.concat([X_train[features], X_test[features]], axis=0)\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05)  # Set the contamination based on data\n",
    "outliers = iso_forest.fit_predict(X_outlier)\n",
    "\n",
    "X_train['outlier'] = np.where(outliers[:len(X_train)] == -1, 1, 0)\n",
    "X_test['outlier'] = np.where(outliers[len(X_train):] == -1, 1, 0)\n",
    "\n",
    "# Filter out the outliers from both training and test sets\n",
    "X_train = X_train[X_train['outlier'] == 0]\n",
    "y_train = y_train[X_train.index]  # Align y_train to X_train after filtering outliers\n",
    "X_test = X_test[X_test['outlier'] == 0]\n",
    "y_test = y_test[X_test.index]  # Align y_test to X_test after filtering outliers\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Shape of X_train:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Shape of y_train:\")\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Handle Multicollinearity using \n",
    "'''\n",
    "features_for_vif = X_train.select_dtypes(include=[np.number]).drop(columns=['outlier'])\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = features_for_vif.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(features_for_vif.values, i) for i in range(len(features_for_vif.columns))]\n",
    "\n",
    "high_vif_features = vif_data[vif_data['VIF'] > 10]\n",
    "print(\"Features with High VIF (>10):\")\n",
    "print(high_vif_features)\n",
    "\n",
    "# Apply PCA to reduce features with high multicollinearity\n",
    "# Keep the features that were not flagged for high VIF\n",
    "features_for_pca = features_for_vif.drop(columns=high_vif_features['Feature'])\n",
    "\n",
    "# Standardize the data before PCA\n",
    "scaler = StandardScaler()\n",
    "scaled_features_train = scaler.fit_transform(X_train[features_for_pca.columns])\n",
    "\n",
    "# Apply PCA to the training data\n",
    "pca = PCA(n_components=0.95)  # Keeps 95% of the variance\n",
    "pca_features_train = pca.fit_transform(scaled_features_train)\n",
    "\n",
    "# Add the PCA-transformed features back to the training dataframe\n",
    "df_pca_train = pd.DataFrame(pca_features_train, columns=[f'PCA_{i+1}' for i in range(pca_features_train.shape[1])])\n",
    "X_train = X_train.reset_index(drop=True)  # Ensure the index is reset before concatenation\n",
    "X_train = pd.concat([X_train, df_pca_train], axis=1)\n",
    "\n",
    "# Apply the same scaler and PCA transformation to the test data\n",
    "scaled_features_test = scaler.transform(X_test[features_for_pca.columns])\n",
    "pca_features_test = pca.transform(scaled_features_test)\n",
    "\n",
    "# Add the PCA-transformed features back to the test dataframe\n",
    "df_pca_test = pd.DataFrame(pca_features_test, columns=[f'PCA_{i+1}' for i in range(pca_features_test.shape[1])])\n",
    "X_test = X_test.reset_index(drop=True)  # Ensure the index is reset before concatenation\n",
    "X_test = pd.concat([X_test, df_pca_test], axis=1)\n",
    "\n",
    "# Optionally drop the original features that were replaced by PCA\n",
    "X_train = X_train.drop(columns=features_for_pca.columns)\n",
    "X_test = X_test.drop(columns=features_for_pca.columns)\n",
    "\n",
    "# Display the updated DataFrame with PCA components\n",
    "print(\"Shape of X_train after PCA:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Shape of y_train:\")\n",
    "print(y_train.shape)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the number of rows in X_train and y_train match after filtering outliers\n",
    "print(\"Shape of X_train after filtering outliers:\", X_test.shape)\n",
    "print(\"Shape of y_train after filtering outliers:\", y_test.shape)\n",
    "\n",
    "# Display a sample of the filtered data to check alignment\n",
    "print(\"\\nSample of filtered X_train:\")\n",
    "print(X_train.head())  # Displaying the first few rows of X_train\n",
    "\n",
    "print(\"\\nCorresponding values in y_train:\")\n",
    "print(y_train.head())  # Displaying the corresponding target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Define a custom scorer\n",
    "scorer = make_scorer(f1_score, pos_label=1)  # Specify `pos_label` if targeting a specific class\n",
    "\n",
    "# Perform GridSearchCV with 5-fold cross-validation and the custom scorer\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=scorer, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best hyperparameters and their corresponding score\n",
    "print(\"Best Hyperparameters from GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best F1 Score:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluate the Model\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "y_test_pred = best_knn.predict(X_test) \n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\") \n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Low Demand', 'High Demand'], yticklabels=['Low Demand', 'High Demand'])\n",
    "plt.title('Confusion Matrix (Test Set)')  \n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Plot ROC Curve and Precision-Recall Curve for our prediction\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_test_prob = best_knn.predict_proba(X_test)[:, 1]  # changed to X_test (no scaling applied)\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line (no discrimination)\n",
    "plt.title('ROC Curve (Test Set)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "avg_precision = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='green', label=f'Precision-Recall curve (AP = {avg_precision:.2f})')\n",
    "plt.title('Precision-Recall Curve (Test Set)')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
