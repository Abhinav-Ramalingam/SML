{"cells":[{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (2.5.1)\n","Requirement already satisfied: torchvision in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (0.20.1)\n","Requirement already satisfied: filelock in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torchvision) (2.1.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/abhinavramalingam/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install torch torchvision"]},{"cell_type":"code","execution_count":16,"metadata":{"tags":[]},"outputs":[],"source":["%matplotlib inline\n","import torch\n","import math\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import matplotlib.pyplot as plt\n","\n","# use GPU for computations if possible\n","device = torch.device('mps' if torch.cuda.is_available() else 'cpu')\n","\n","# temporarily patch this script until the MNIST data set download issue is resolved\n","# https://github.com/pytorch/vision/issues/1938\n","import urllib.request\n","opener = urllib.request.build_opener()\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n","urllib.request.install_opener(opener)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"2ZfaQIUpDZvO","tags":[]},"source":["# Classification of hand-written digits\n","\n","We start by downloading and extracting the MNIST data set."]},{"cell_type":"code","execution_count":17,"metadata":{"scrolled":false,"tags":[]},"outputs":[],"source":["trainset = torchvision.datasets.MNIST(root='./data', train=True,\n","                                      download=True, transform=transforms.ToTensor())\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                     download=True, transform=transforms.ToTensor())\n","\n","# extract a complete PyTorch dataset\n","def extract(dataset):\n","    datasize = len(dataset)\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=datasize, shuffle=False)\n","    return next(iter(dataloader))\n","\n","# extract all test images and labels into PyTorch tensors\n","# the training data will be loaded in batches during training\n","test_X, test_Y = extract(testset)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JetLsyAjDZv3","tags":[]},"source":["## The model\n","\n","The input data $X$ are grayscale images of $28\\times 28$ pixels. The first dimension will be the number of data points that are provided to the network. The input data is flattend into a matrix with $28 \\times 28 = 784$ columns using `X.view(-1, 784)`, where each colum represents one pixel. We then apply first the linear transformation $X W + b$ and then the softmax function to obtain the class probabilities predicted by the model."]},{"cell_type":"code","execution_count":18,"metadata":{"tags":[]},"outputs":[],"source":["# U4 = 588 (no of flattened input units from convo2d into the first dense)\n","\n","class Net(nn.Module):\n","    def __init__(self, U1=4, U2=8, U3=12, U4=588, U5=200):\n","        super(Net, self).__init__()\n"," \n","        self.W1 = nn.Parameter(0.1 * torch.randn(U1, 1, 5, 5))\n","        self.b1 = nn.Parameter(0.1 * torch.ones(U1))\n","        self.W2 = nn.Parameter(0.1 * torch.randn(U2, 4, 5, 5))\n","        self.b2 = nn.Parameter(0.1 * torch.ones(U2))\n","        self.W3 = nn.Parameter(0.1 * torch.randn(U3, 8, 4, 4))\n","        self.b3 = nn.Parameter(0.1 * torch.ones(U3))\n","        self.W4 = nn.Parameter(0.1 * torch.randn(U4, U5))\n","        self.b4 = nn.Parameter(0.1 * torch.ones(U5))\n","        self.W5 = nn.Parameter(0.1 * torch.randn(U5, 10))\n","        self.b5 = nn.Parameter(0.1 * torch.ones(10))\n","\n","    def forward(self, X):\n","        # compute the hidden layer\n","        Q1 = F.relu(F.conv2d(X, self.W1, bias=self.b1, stride=1, padding=2))\n","        Q2 = F.relu(F.conv2d(Q1, self.W2, bias=self.b2, stride=2, padding=2))\n","        Q3 = F.relu(F.conv2d(Q2, self.W3, bias=self.b3, stride=2, padding=1))\n","        Q3flat = Q3.view(-1, 588)\n","        Q4 = F.relu(Q3flat.mm(self.W4) + self.b4)\n","        Z = Q4.mm(self.W5) + self.b5\n","        return Z"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NYMZmV_GDZwa","tags":[]},"source":["## The training\n","\n","We define the cross-entropy for the predicted probabilities $G$ (10-dimensional vectors) and the labels $Y$ (integers between 0 and 9)."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{},"colab_type":"code","id":"cOpD7LKcDZwe","tags":[]},"outputs":[],"source":["def crossentropy(G, Y):\n","    # convert labels to onehot encoding\n","    Y_onehot = torch.eye(10, device=device)[Y]\n","\n","    return -(Y_onehot * G.log()).sum(dim = 1).mean()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vSpeO0byDZwx","tags":[]},"source":["The next lines evaluate the accuracy of the predictions."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{},"colab_type":"code","id":"G1B5xLOnDZw0","tags":[]},"outputs":[],"source":["def accuracy(G, Y):\n","    return (G.argmax(dim=1) == Y).float().mean()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"rJ4jX9FDDZxB","tags":[]},"source":["We are ready to train the network."]},{"cell_type":"code","execution_count":22,"metadata":{"scrolled":false,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Step     0: train accuracy   7.00% train cross-entropy  2.39  test accuracy   9.35% test cross-entropy  2.36 learning rate 0.003\n","Step   100: train accuracy  93.00% train cross-entropy  0.27  test accuracy  93.25% test cross-entropy  0.21 learning rate 0.003\n","Step   200: train accuracy  95.00% train cross-entropy  0.26  test accuracy  95.92% test cross-entropy  0.14 learning rate 0.003\n","Step   300: train accuracy  96.00% train cross-entropy  0.12  test accuracy  96.13% test cross-entropy  0.12 learning rate 0.003\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m test_X\u001b[38;5;241m.\u001b[39mto(device), test_Y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# compute predictions for the test data\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m test_crossentropy\u001b[38;5;241m.\u001b[39mappend(F\u001b[38;5;241m.\u001b[39mcross_entropy(G, Y)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     66\u001b[0m test_accuracy\u001b[38;5;241m.\u001b[39mappend(accuracy(G, Y)\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m~/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Documents/Uppsala/SML/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[0;32mIn[18], line 21\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# compute the hidden layer\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     Q1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39mconv2d(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW1, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m     Q2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m     Q3 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39mconv2d(Q2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW3, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb3, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     23\u001b[0m     Q3flat \u001b[38;5;241m=\u001b[39m Q3\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m588\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# initialize the test and training error statistics\n","test_accuracy = []\n","test_crossentropy = []\n","test_iter = []\n","train_accuracy = []\n","train_crossentropy = []\n","train_iter = []\n","\n","# initialize the neural network and move it to the GPU if needed\n","net = Net()\n","net.to(device)\n","\n","# define the optimization algorithm\n","lr_min = 0.0001\n","lr_max = 0.003\n","lr = lr_max\n","optimizer = optim.Adam(net.parameters(), lr=lr)\n","\n","# define the data loader for batches of the training data\n","batchsize = 100\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, num_workers=2, shuffle=True)\n","\n","# perform multiple training steps\n","total_iterations = 4000  # total number of iterations\n","t = 0  # current iteration\n","done = False\n","while not done:\n","    if t > 0:\n","        print('t=',t)\n","        lr = lr_min + (lr_max - lr_min) * math.exp(-t / 2000.00)\n","        # update the learning rate in the optimizer\n","    optimizer = optim.Adam(net.parameters(), lr=lr)\n","    \n","    for (batch_X, batch_Y) in trainloader:\n","        # move batch to the GPU if needed\n","        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        batch_G = net(batch_X)\n","        loss = F.cross_entropy(batch_G, batch_Y)\n","\n","        # backpropagation\n","        loss.backward()\n","        \n","        # perform gradient descent step\n","        optimizer.step()\n","        \n","        # evaluate the performance on the training data at every 10th iteration\n","        with torch.no_grad():\n","            if t % 10 == 0:\n","                train_crossentropy.append(loss.item())\n","                train_accuracy.append(accuracy(batch_G, batch_Y).item())\n","                train_iter.append(t)\n","                \n","            # evaluate the performance on the test data at every 100th iteration\n","            if t % 100 == 0:\n","                # move test data to the GPU if needed\n","                X, Y = test_X.to(device), test_Y.to(device)\n","\n","                # compute predictions for the test data\n","                G = net(X)\n","                test_crossentropy.append(F.cross_entropy(G, Y).item())\n","                test_accuracy.append(accuracy(G, Y).item())\n","                test_iter.append(t)\n","\n","                # print the iteration number and the accuracy of the predictions\n","                print(f\"Step {t:5d}: train accuracy {100 * train_accuracy[-1]:6.2f}% \" \\\n","                      f\"train cross-entropy {train_crossentropy[-1]:5.2f}  \" \\\n","                      f\"test accuracy {100 * test_accuracy[-1]:6.2f}% \" \\\n","                      f\"test cross-entropy {test_crossentropy[-1]:5.2f} \" \\\n","                      f\"learning rate {lr}\")\n","                \n","\n","        # stop the training after the specified number of iterations\n","        t += 1\n","        if t > total_iterations:\n","            done = True\n","            break\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wY9MEi2xDZxM","tags":[]},"source":["## The evaluation\n","\n","The remaining code produces the plots needed to evaluate the training and predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":735},"colab_type":"code","id":"L_MSLJvoD28u","outputId":"2be25bd3-0568-4590-faa2-39de35251d61","tags":[]},"outputs":[],"source":["# plot the cross-entropy\n","plt.plot(train_iter, train_crossentropy, 'b-', label='Training data (mini-batch)')\n","plt.plot(test_iter, test_crossentropy, 'r-', label='Test data')\n","plt.xlabel('Iteration')\n","plt.ylabel('Cross-entropy')\n","plt.ylim([0, min(test_crossentropy) * 3])\n","plt.title('Cross-entropy')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","# plot the accuracy\n","plt.plot(train_iter, train_accuracy, 'b-', label='Training data (mini-batch)')\n","plt.plot(test_iter, test_accuracy, 'r-', label='Test data')\n","plt.xlabel('Iteration')\n","plt.ylabel('Prediction accuracy')\n","plt.ylim([max(1 - (1 - test_accuracy[-1]) * 2, 0), 1])\n","plt.title('Prediction accuracy')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"colab_type":"code","id":"caWJ8PwaDZxO","outputId":"1d3e738d-e278-425a-ddb7-bcda6a4565f4","scrolled":false,"tags":[]},"outputs":[],"source":["# evaluate the network on 100 random test images\n","with torch.no_grad():\n","    # obtain 100 random samples from the test data set\n","    random_X, random_Y = next(iter(torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True)))\n","    \n","    # move data to the GPU if needed\n","    random_X, random_Y = random_X.to(device), random_Y.to(device)\n","    \n","    # compute the predictions for the sampled inputs\n","    random_G = net(random_X)\n","    random_Yhat = random_G.argmax(dim=1)\n","\n","    # sort the predictions with the incorrect ones first\n","    indices_incorrect_first = (random_Yhat == random_Y).float().argsort()\n","\n","# plot the images\n","num_rows = 10\n","num_cols = 10\n","num_images = num_rows * num_cols\n","plt.figure(figsize=(num_cols, num_rows))\n","\n","for i, index in enumerate(indices_incorrect_first, 1):\n","    plt.subplot(num_rows, num_cols, i)\n","    plt.xticks([])\n","    plt.yticks([])\n","    \n","    # plot the image\n","    plt.imshow(random_X[index, :, :].view(28, 28).cpu().numpy(), cmap=plt.cm.binary)\n","    \n","    # add the prediction as annotation (incorrect predictions in red, correct ones in blue)\n","    color = 'blue' if random_Yhat[index] == random_Y[index] else 'red'\n","    plt.text(0, 25, random_Yhat[index].item(), fontsize=25, color=color)\n","        \n","plt.show()"]}],"metadata":{"@webio":{"lastCommId":null,"lastKernelId":null},"anaconda-cloud":{},"celltoolbar":"Tags","colab":{"name":"mnist_one_layer.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":1}
